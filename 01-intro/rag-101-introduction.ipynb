{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f4f9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e91f0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6ffd81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents-llm.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4a1b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (docs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3416d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c6794a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Yes, but if you want to receive a certificate, you need to submit your project while we’re still accepting submissions.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'I just discovered the course. Can I still join?',\n",
       " 'course': 'llm-zoomcamp'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff4ea248",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42f6e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'The course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c2f216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7b7149305420>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "af38b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "results = index.search(\n",
    "    query=q,\n",
    "    filter_dict={'course': 'llm-zoomcamp'},\n",
    "    boost_dict=boost,\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1add26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "59325531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()  # This loads from .env file\n",
    "# api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "# if not api_key:\n",
    "#     raise ValueError(\"GROQ_API_KEY environment variable not set\")\n",
    "\n",
    "# client = Groq(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cbc732df",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d1faa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": q\n",
    "        }\n",
    "    ],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d407088d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It depends on the course and institution. Some courses may allow late enrollment, while others may not. I'd recommend checking with the institution or course provider directly to see if late enrollment is possible. They may have specific deadlines or requirements for late enrollment, so it's best to reach out to them for more information. \\n\\nYou can try contacting the course administrator, instructor, or admissions office to inquire about the possibility of late enrollment. They can provide you with more details on the enrollment process, any potential penalties or fees, and what you can expect if you're allowed to join the course after it has started.\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a56fc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a6a774c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f20629e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=q, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c71da311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "514eaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'llm-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954e96a",
   "metadata": {},
   "source": [
    "<!-- # If the CONTEXT doesn't contain the answer, output NONE. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a38057e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a2872328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    \n",
    ")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9baafe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c8507985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The course will start in Summer 2025.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"How to configure apache spark?\"\n",
    "query = \"When does the course  will start?\"\n",
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b4fa15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saturn Cloud is not defined in the provided context, but it is mentioned in several sections, particularly in relation to Open-Source LLMs and as an alternative to other cloud services. It appears to be a cloud platform that can be used for notebook operations and has a cache that can be cleaned out using specific code. However, a clear definition of what Saturn Cloud is, is not provided in the given context.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"What is saturn cloud?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb2a3dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Yes, but if you want to receive a certificate, you need to submit your project while we’re still accepting submissions.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'I just discovered the course. Can I still join?',\n",
       " 'course': 'llm-zoomcamp'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "afa493e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d2bfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "76c9997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "# es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "632e0698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Yes, but if you want to receive a certificate, you need to submit your project while we’re still accepting submissions.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'I just discovered the course. Can I still join?',\n",
       " 'course': 'llm-zoomcamp'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d75144a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a565d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095d81154fd340b6bd7ec572eb06fac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8ac0310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When does the course  will start?'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"When does the course  will start?\"\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "80eedfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "\n",
    "    search_query = {\n",
    "            \"size\": 5,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                            \"type\": \"best_fields\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"course\": \"llm-zoomcamp\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append({\n",
    "            'source': hit['_source'],\n",
    "            'score': hit['_score']\n",
    "            })\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b5477c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elastic_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "02ff9332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': {'text': 'You can use any LLM platform for your experiments and your project. Also, the homework is designed in such a way that you don’t need to have access to any paid services and can do it locally. However, you would need to adjust the code for that platform. See their documentation pages.',\n",
       "   'section': 'Module 1: Introduction',\n",
       "   'question': 'OpenSource: Can I use Groq instead of OpenAI?',\n",
       "   'course': 'llm-zoomcamp'},\n",
       "  'score': 12.423037},\n",
       " {'source': {'text': \"The question asks for the number of tokens in gpt-4o model. tiktoken is a python library that can be used to get the number of tokens. You don't need openai api key to to get the number of tokens. You can use the code provided in the question to get the number of tokens.\",\n",
       "   'section': 'Module 1: Introduction',\n",
       "   'question': \"OpenSource: I am using Groq, and it doesn't provide a tokenizer library based on my research. How can we estimate the number of OpenAI tokens asked in homework question 6?\",\n",
       "   'course': 'llm-zoomcamp'},\n",
       "  'score': 11.911271},\n",
       " {'source': {'text': 'The last version I checked for CUDA was 12.5 using a cloud environment like Saturn Cloud. Then the torch package for python should be on supported for that version of CUDA, is followed by cu121 which means that version of torch supports cuda 12.1. Check this page to find the package and version available for CUDA (remember to search the keyword “cu”\\nIn my case I focused on using a torch==2.3.1 and the last cuda version supported was 12.1 (it works on Saturn Cloud)\\nTo install all the needed packages use this command:\\n!pip install transformers accelerate torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 --trusted-host download.pytorch.org --index-url https://download.pytorch.org/whl/cu121\\nAnd after that just executed this command:\\n!pip install --upgrade transformers',\n",
       "   'section': 'Module 3: X',\n",
       "   'question': 'How to run a model using CUDA for GPU usage?',\n",
       "   'course': 'llm-zoomcamp'},\n",
       "  'score': 8.967183},\n",
       " {'source': {'text': 'In Docker Desktop, try to increase the resource.\\nGo to the Dashboard > Settings > Resources. Raise the memory limit to 15GB and swap to 4GB - be generous. Applied and restarted the changes\\nAdded by Dandy Arif Rahman',\n",
       "   'section': 'Module 2: Open-Source LLMs',\n",
       "   'question': 'Docker: Why does inferring using Phi 3 locally take so long on Macbook Air M1?',\n",
       "   'course': 'llm-zoomcamp'},\n",
       "  'score': 7.598283},\n",
       " {'source': {'text': 'Prior to using Ollama models in llm-zoomcamp tasks, you need to have ollama installed on your pc and the relevant LLM model downloaded with ollama from https://www.ollama.com\\nTo download ollama for Ubuntu:\\n``` curl -fsSL https://ollama.com/install.sh | sh ```\\nTo download ollama for Mac and Windows, follow the guide on this link:\\nhttps://ollama.com/download/\\nOllama a number of open-source LLMs like:\\nLlama3\\nPhi3\\nMistral and Mixtral\\nGemma\\nQwen\\nYou can explore more models on https://ollama.com/library/\\nTo download a model in Ollama, simply open command prompt and type:\\n``` ollama run model_name ```\\ne.g.\\n``` ollama run phi3 ```\\nIt will automatically download the model and you can use it same way as above for later time.\\nTo use Ollama models for inference and llm-zoomcamp tasks, use the following function:\\nimport ollama\\ndef llm(prompt):\\nresponse = ollama.chat(\\nmodel=\"llama3\",\\nmessages=[{\"role\": \"user\", \"content\": prompt}]\\n)\\nreturn response[\\'message\\'][\\'content\\']\\nFor example, we can use it in the following way:\\nprompt = \"When does the llm-zoomcamp course start?\"\\nanswer = llm(prompt)\\nprint(answer)',\n",
       "   'section': 'Module 1: Introduction',\n",
       "   'question': 'OpenSource: How can I use Ollama open-source models locally on my pc without using any API?',\n",
       "   'course': 'llm-zoomcamp'},\n",
       "  'score': 7.1610117}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search(\"token using groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825de2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag(\"How to use tokenizer library?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
